class BaseReqRefInfo:
    def __init__(self, charactor, opid, op_type,):
        self.charactor = charactor
        self.opid = opid
        self.op_type = op_type

class Requirements:
    def __init__(self, handle, size, first_time_used, last_time_used):
        self.handle = handle
        self.size = size
        self.first_time_used = first_time_used
        self.last_time_used = last_time_used
        self.additional_infos = []
        self.priority = 0
        self.memory_requirement = -1
        self.preprocs = []
        self.postprocs = []
        self.ref_infos = []
    def __eq__(self, other):
        return (self.priority == other.priority and
            self.size == other.size and
            self.first_time_used == other.first_time_used and
            self.last_time_used == other.last_time_used)  
    def __lt__(self, other):
        if (self.priority != other.priority):
            return self.priority < other.priority
        elif(self.size != other.size):
            # large buffer first
            return self.size < other.size
        elif (self.first_time_used != other.first_time_used):
            # earlier used buffer first
            return self.first_time_used > other.first_time_used
        elif (self.last_time_used != other.last_time_used):
            # earlier freed buffer first
            return self.last_time_used > other.last_time_used
        else:
            return False
    def AttachAddons(self, additional_info, preproc, postproc):
        self.additional_infos.append(additional_info)
        self.preprocs.append(preproc)
        self.postprocs.append(postproc)
    def AttachRefInfo(self, ref_info:BaseReqRefInfo):
        self.ref_infos.append(ref_info)

class TFLM_Greedy_Planner:
    def __init__(self):
        self.plan_created = False
        self.offset_calculated = False
        self.offset_committed = False
        self.requirements = []
    
    # Input requirements for memory planning
    def CreatePlan(self, requirements):
        self.plan_created = True
        self.offset_calculated = False
        self.offset_committed = False
        self.requirements = requirements

    # Do memory planning with the buffer requirements generated by CreatePlan
    def CalculateOffset(self):
        def isOverlapInTime(target_req, candidate_entry):
            if target_req.first_time_used > candidate_entry.last_time_used:
                return False
            if candidate_entry.first_time_used > target_req.last_time_used:
                return False
            return True

        def get_next_gap(req,start):
            if start == -1:
                candidate_next = 0
            else:
                candidate_next = start+1
            # find a time overlapped entry
            while(candidate_next < len(self.req_id_offset_sorted)):
                candidate_next_req_id = self.req_id_offset_sorted[candidate_next]
                candidate_next_req = self.requirements[candidate_next_req_id]
                if isOverlapInTime(req, candidate_next_req):
                    return candidate_next
                candidate_next += 1
            return -1 # reach the end, no time overlapped entry

        def get_gap(req):
            prior_entry = -1
            candidate_offset = 0
            while 1:
                next_entry = get_next_gap(req, prior_entry)
                # no fine gap between allocated buffer, so append in the back
                if next_entry == -1:
                    break
                next_entry_req_id = self.req_id_offset_sorted[next_entry]
                next_entry_offset = self.calculated_offset[next_entry_req_id]
                gap_size = next_entry_offset - candidate_offset
                # fine gap
                if gap_size >= req.size:
                    break
                # bad gap
                next_entry_size = self.requirements[next_entry_req_id].size
                next_entry_tail = next_entry_offset + next_entry_size
                if next_entry_tail > candidate_offset:
                    candidate_offset = next_entry_tail
                prior_entry = next_entry
            return candidate_offset
            
        def save_result(req_id, offset):
            # first, validate result
                # assume no error, skip
            # second, save it in calculated_offset
            self.calculated_offset[req_id] = offset
            # third, insert into self.req_id_offset_sorted
            insert_point = 0
            for current_req_id in self.req_id_offset_sorted:
                if self.calculated_offset[current_req_id] > self.calculated_offset[req_id]:
                    break
                insert_point+=1
            self.req_id_offset_sorted.insert(insert_point, req_id)
        if self.offset_calculated:
            return
        if not self.plan_created:
            raise BaseException("should CreatePlan first")
        self.offset_committed = False
        self.offset_calculated = True
        self.memory_requirement = -1

        # python impl of TFLM Greedy Planner
        self.calculated_offset = [-1 for _ in range(len(self.requirements))]
        req_id_size_sorted = sorted([x for x in range(len(self.requirements))], reverse=True,
                                    key=lambda x: self.requirements[x])
        self.req_id_offset_sorted = [] # for searching gap

        # Start planning
        # Directly insert the largest size req
        first_req_id = req_id_size_sorted[0]
        first_req = self.requirements[first_req_id]
        for addon_id, preproc in enumerate(first_req.preprocs):
            preproc(self, first_req_id, addon_id)
        save_result(first_req_id, 0)
        for addon_id, postproc in enumerate(first_req.postprocs):
            postproc(self, first_req_id, addon_id)
        # Continue planning process
        for req_id in req_id_size_sorted[1:]:
            req = self.requirements[req_id]
            if self.calculated_offset[req_id] != -1:
                continue
            for addon_id, preproc in enumerate(req.preprocs):
                preproc(self, req_id, addon_id)
            if self.calculated_offset[req_id] != -1:
                continue
            offset = get_gap(req)
            save_result(req_id, offset)
            for addon_id, postproc in enumerate(req.postprocs):
                postproc(self, req_id, addon_id)

    # return requirements with calculated offset
    def GetPlannedResult(self):
        if not self.offset_calculated:
            self.CalculateOffset()
        return self.requirements, self.calculated_offset

    def GetMaximumMemorySize(self):
        def get_tail(head, size):
            # assume head is aligned
            return head+size
        if not self.offset_calculated:
            self.CalculateOffset()
        if self.memory_requirement == -1:
            self.memory_requirement = max([get_tail(head, req.size) for head, req in zip(self.calculated_offset, self.requirements)])
        return self.memory_requirement

    def PlotResult(self, model_name):
        # import modules
        import matplotlib.pyplot as plt
        import matplotlib.pyplot as patches
        import matplotlib.pyplot as img
        import matplotlib.ticker as ticker
        from PIL import Image
        # Plot
        fig, ax = plt.subplots()

        def getcmap(n, name='Spectral'):
            return plt.cm.get_cmap(name, n)

        records = [(i, offset, req.first_time_used, req.size, req.last_time_used - req.first_time_used + 1, req) for i, (req, offset) in enumerate(zip(self.requirements, self.calculated_offset))]
        cmap = getcmap(len(records) + 1)

        max_offset = 0

        for i, r in enumerate(records):
            m = cmap(i)
            if isinstance(r[5].handle, tuple):
                sid_tmp = r[5].handle[1]
                if sid_tmp == -1:
                    m = 'gray'
            else:
                m = 'gray'

            rect = patches.Rectangle(
                (r[1], r[2]), r[3], r[4],
                facecolor = m, ec='black', lw=0.05,
                fill=True,
                label=str(r[0]),
            )

            req = r[5]
            if isinstance(req.handle, tuple):
                tid = req.handle[0]
                sid = req.handle[1]
                plt.text(r[1], r[2]+1, f'{tid},{sid}',fontsize=0.5)

            max_offset = max(max_offset, r[2] + r[4])
            ax.add_patch(rect)

        ax.set_xlim(0, self.GetMaximumMemorySize())
        ax.set_ylim(0, max_offset)
        ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))
        ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))
        ax.ticklabel_format(scilimits=(-3,3))
        ax.xaxis.tick_top()
        ax.xaxis.set_label_position('top')
        ax.invert_yaxis()
        plt.xlabel('arena')
        plt.ylabel('OPs')
        plt.title(model_name, y = -0.1)
        plt.text(0,0, str(self.GetMaximumMemorySize()), transform=fig.transFigure)
        plt.savefig(model_name + '.png', dpi=1600)

